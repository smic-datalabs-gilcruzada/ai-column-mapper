{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bdea2f4-39f3-4c5a-beda-7abd00f31125",
   "metadata": {
    "tags": []
   },
   "source": [
    "# PaLM2 Few-Shot Prompting and RAG Proof-of-Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f15c4d-6b1f-4bb1-bd5e-d75580ab895c",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f165c2-bf9a-4a16-a03b-28da1d5f4f8a",
   "metadata": {},
   "source": [
    "##### This notebook will serve as a local test ground to evaluate the PaLM2 fine-tuned model with RAG for column-mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2977c437-cf79-41b6-bd03-91709f5774dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c4925a8-d69e-4705-bdc0-efd13185139b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# General\n",
    "import csv\n",
    "import numpy as np\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "# Import the Vertex AI SDK for Python\n",
    "from langchain_google_vertexai import VertexAI\n",
    "\n",
    "## langchain dependencies\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain import hub\n",
    "# from langchain_community.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.document_loaders.base import BaseLoader\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "# Vectorstore and Embeddings\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ed9631-7e1e-4499-85ee-d1bcd6c7970c",
   "metadata": {},
   "source": [
    "## Configuring Environment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54d32dd9-3da3-4d4a-8037-f41af4172fcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Project definitions\n",
    "PROJECT_ID = \"dlabs-intelligent-col-mapper\"  # @param {type:\"string\"}\n",
    "REGION = \"asia-southeast1\"  # @param {type: \"string\"}\n",
    "\n",
    "# vertex_ai.init(project=PROJECT_ID, location=REGION)\n",
    "# print(vertex_ai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da5129f-9d58-48b5-97ef-6d57bcea13d9",
   "metadata": {},
   "source": [
    "## RAG Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c555fa0-61a1-4d2b-b21e-0fb881832f55",
   "metadata": {},
   "source": [
    "### Customized CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "53f26e48-3a7c-41f3-a9a9-311c6bcd4ac3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CSVLoader(BaseLoader):\n",
    "    \"\"\"Loads a CSV file into a list of documents.\n",
    "\n",
    "    Each document represents one row of the CSV file. Every row is converted into a\n",
    "    key/value pair and outputted to a new line in the document's page_content.\n",
    "\n",
    "    The source for each document loaded from csv is set to the value of the\n",
    "    `file_path` argument for all doucments by default.\n",
    "    You can override this by setting the `source_column` argument to the\n",
    "    name of a column in the CSV file.\n",
    "    The source of each document will then be set to the value of the column\n",
    "    with the name specified in `source_column`.\n",
    "\n",
    "    Output Example:\n",
    "        .. code-block:: txt\n",
    "\n",
    "            column1: value1\n",
    "            column2: value2\n",
    "            column3: value3\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        file_path: str,\n",
    "        source_column: Optional[str] = None,\n",
    "        metadata_columns: Optional[List[str]] = None,   # < ADDED\n",
    "        csv_args: Optional[Dict] = None,\n",
    "        encoding: Optional[str] = None,\n",
    "    ):\n",
    "        self.file_path = file_path\n",
    "        self.source_column = source_column\n",
    "        self.encoding = encoding\n",
    "        self.csv_args = csv_args or {}\n",
    "        self.metadata_columns = metadata_columns        # < ADDED\n",
    "\n",
    "    def load(self) -> List[Document]:\n",
    "        \"\"\"Load data into document objects.\"\"\"\n",
    "\n",
    "        docs = []\n",
    "        with open(self.file_path, newline=\"\", encoding=self.encoding) as csvfile:\n",
    "            csv_reader = csv.DictReader(csvfile, **self.csv_args)  # type: ignore\n",
    "            for i, row in enumerate(csv_reader):\n",
    "                content = \"\\n\".join(f\"{k.strip()}: {v.strip()}\" for k, v in row.items() if k == \"Source column name\")\n",
    "                try:\n",
    "                    source = (\n",
    "                        row[self.source_column]\n",
    "                        if self.source_column is not None\n",
    "                        else self.file_path\n",
    "                    )\n",
    "                except KeyError:\n",
    "                    raise ValueError(\n",
    "                        f\"Source column '{self.source_column}' not found in CSV file.\"\n",
    "                    )\n",
    "                metadata = {\"source\": source, \"row\": i}\n",
    "                # ADDED TO SAVE METADATA\n",
    "                if self.metadata_columns:\n",
    "                    # print(self.metadata_columns)\n",
    "                    for k, v in row.items():\n",
    "                        #print(k)\n",
    "                        if k in self.metadata_columns:\n",
    "                            #print(k)\n",
    "                            metadata[k] = v\n",
    "                            #print(metadata[k])\n",
    "                # END OF ADDED CODE\n",
    "                doc = Document(page_content=content, metadata=metadata)\n",
    "                docs.append(doc)\n",
    "\n",
    "        return docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97f357f-88c8-41af-8ef9-d09353ce8b33",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "66179bc8-d146-492b-8687-1b994c869f95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "excel_file = r\"C:\\Users\\gil.cruzada\\Desktop\\Column-Mapper\\dev-ground\\cm-dev-dataset\\copy_dm.csv\"\n",
    "loader = CSVLoader(file_path = excel_file, source_column = 'target_column', metadata_columns = ['data_type','target_table'])\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c9b6be8-00aa-44c1-bc43-ecf956cd3bb1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Split documents\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 0)\n",
    "# splits = text_splitter.split_documents(data)\n",
    "# splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b1feaa6-067e-4bfd-b465-9671777eea1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model_name will become a required arg for VertexAIEmbeddings starting from Feb-01-2024. Currently the default is set to textembedding-gecko@001\n"
     ]
    }
   ],
   "source": [
    "# Defining embedding object\n",
    "embeddings = VertexAIEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589921c3-820d-4d5e-98ce-98b1029c0bbe",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Vector Database through Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c5da45a4-c4c3-412a-91e8-363e3a997b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectore store\n",
    "chroma_vectorstore = Chroma.from_documents(splits, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b2ffd740-e228-48f4-b848-ff34a70049ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create Retriever\n",
    "chroma_retreiver = chroma_vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f4f4f7-a524-4a2b-9b7b-3349db4f805a",
   "metadata": {},
   "source": [
    "### Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4355ddfa-bae0-4d42-a45d-46153e539ab7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#llm = VertexAI(model_name='text-unicorn@001')\n",
    "llm = VertexAI(model_name='text-bison@001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0b00f409-78b3-4000-9478-1f52eb573569",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "past index rag_prompt creation \n"
     ]
    }
   ],
   "source": [
    "rag_prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5194f3-6c9c-45aa-af06-61bc59de9e90",
   "metadata": {},
   "source": [
    "### with RAG prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "19df10ca-11a4-4ea6-924e-8959d83c2af3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Given the input below you are tasked with mapping a source column to its target column. You must take strictly account take into account \n",
    "the sample values, data type, source_table, and source column in your task of column mapping. \n",
    "Take priority in mapping a source column first to its target column. The structure of your output should look like the example outputs below. \n",
    "Strictly maintain the output structure.\n",
    "\n",
    "input: source_column: branch, source_table: journal_header, data_type: integer, sample: [\"1927\",\"1563\", \"410\"]\n",
    "output: target_column: branch_key, target_table: fct_header\n",
    "      \n",
    "input: source_column: company, source_table: dim_store, data_type: string, sample: [\"MARKET STRATEGIC FIRM, INC.\", \"MERIDIEN BUSINESS LEADER, INC.\", \"MERCANTILE STORES GROUP, INC.\"]\n",
    "output: target_column: company_name, target_table: dim_company\n",
    "      \n",
    "input: source_column: line_amt1, source_table: journal_details, data_type: float, sample: [\"185.25\", \"122.50\", \"95.18\"]\n",
    "output: target_column: amount, target_table: fct_sku\n",
    "      \n",
    "input: source_column: upload_date, source_table: csa_fct_header, data_type: timestamp, sample: [\"2023-04-29 03:10:46.110000\", \"2023-08-26 03:02:31.057000\", \"2023-09-18 03:50:44.760000\"]\n",
    "output: target_column: created_date, target_table: fct_transaction\n",
    "\n",
    "input: source_column: arc_date, source_table: dim_store, data_type: date, sample: [\"2023-06-22\", \"2023-12-28\", \"2021-10-38\"]\n",
    "output: target_column: created_date, target_table: fct_transaction\n",
    "      \n",
    "input: source_column: qty, source_table: csa_fct_merchandise, data_type: float, sample: [\"27.0\", \"1.0\", \"13.0\"]\n",
    "output: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c3d416ed-205c-45fe-b386-8620cf4b8e09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_2 = \"\"\"\n",
    "What is the closet target_column for our source_column: arc_date?. Justify your answer\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "76fcdb2b-0a2f-4114-9d42-b7c17e4f9b5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rci_output is:  target_column: quantity, target_table: fct_sku\n"
     ]
    }
   ],
   "source": [
    "# RAG chain \n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "rag_chain = (\n",
    "    {\"context\": chroma_vectorstore.as_retriever(), \"question\": RunnablePassthrough()} \n",
    "    | rag_prompt \n",
    "    | llm \n",
    ")\n",
    "\n",
    "rci_output = rag_chain.invoke(prompt)\n",
    "print(\"rci_output is: \", rci_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
